	<h1><span>Цели проекта</span></h1>

	<div class="block">
		<p><strong>CBSD</strong> разрабатывалась с точки зрения user-friendly, с учетом удобств для пользователя при интерактивной работе. Вы можете спросить - что ж, интерактивные диалоги -
		это прекрасно. Но что, если у вас стоит задача построить масштабируемый кластер, где виртуальными машинами будет управлять логика более высокого уровня и по этой причине, 
		нам нет нужды в интерактивных командах - может ли <strong>CBSD</strong> чем-то быть вам полезной в этом случае?</p>
		<p>В этой статье описан пример создания и управления кластером <strong>CBSD</strong> через асинхронный интерфейс с использованием минималистического и быстрого брокера на базе <a target="_blank" href="http://xph.us/software/beanstalkd/">net/beanstalkd</a>.
		Вместо <strong>beanstalkd</strong> может выступать любой брокер, такой как ActiveMQ, ZeroMQ, RabbitMQ или Kafka.
		Условно, назовем это низким уровенем управления виртуальными машинами, который обеспечивает доставку и возвращение результата при управлении виртуальными машинами, такие как создание ВМ, 
		добавление диска, создание снапшота, миграция, клонирование, изменение VNC порта и тд. На более высоком уровне может быть ваше приложение (контроллер).</p>
		<p>Здесь мы будем использовать множественные рабочие окружения <strong>CBSD</strong>, когда часть ресурсов может быть проинициализирована в одном каталоге, другая - в другом.
		Это открывает широкие возможности при построении pool-binded методов размещения виртуальных машин.
		Pool binded кластер означает, что все сервисы или виртуальные машины кластера будут привязаны к тому или иному пулу,
		который может переходить от одного сервера к другому при аварийных ситуациях, при работе DRS или обслуживания оборудования.
		Таким образом, это может стать базой для построения 'shared nothing cluster' на базе FreeBSD и <strong>CBSD</strong>.</p>
		<img src="/img/cbsd_pool_mq1.png" alt="" />
		<p>Построение отказоустойчивого кластера будет описано в более расширенной статье, здесь мы ограничимся лишь множественными рабочими окружениями <strong>CBSD</strong>, чтобы продемонстрировать работу асинхронного интерфейса через брокер.
		Предполагаем, что <strong>CBSD</strong> уже установлена и настроена на сервере. Нам необходим сервис <strong>beanstalkd</strong>, выступающий в качестве общей шины для всех агентов.
		Давайте запустим его в jail на нашем сервере. Для этого создаем jail с произвольным именем, в котором будет запущен <strong>beanstalkd</strong>, 
		например <strong>bs1</strong> (назначьте контейнеру корректный рабочий IP адрес, он нам потребуется):</p>
		<img src="/img/cbsd_pool_mq2.png" alt="" />
		<pre class="brush:bash;ruler:true;">
		cbsd jconstruct-tui
		cbsd pkg jname=bs1 mode=update
		cbsd pkg jname=bs1 mode=install net/beanstalkd
		cbsd sysrc jname=bs1 beanstalkd_enable=YES
		cbsd jstart bs1
		</pre>
		<p>Затем, проинициализируем два независимых окружения (в настоящем кластере это могут быть разные пулы и их, разумеется, может быть больше), например в /pool1 и /pool2 директориях:</p>
		<pre class="brush:bash;ruler:true;">
		env workdir=/pool1 /usr/local/cbsd/sudoexec/initenv
		</pre>
		<p>на вопрос изменения rc.conf файла, отвечайте 'n', эта инициализация не должна модифицировать ваши основные конфигурационные файлы.</p>
		<p>на вопрос включения NAT ( nat_enable: Enable NAT for RFC1918 networks? ) отвечайте 'нет' - у вас он уже должен работать в основной системе.</p>
		<p>Тоже самое повторите для второго окружения:</p>
		<pre class="brush:bash;ruler:true;">
		env workdir=/pool2 /usr/local/cbsd/sudoexec/initenv
		</pre>
		<p>с аналогичными ответами.</p>
		<p>Теперь, <strong>CBSD</strong> может работать в этих окружениях через переменную workdir, например:</p>
		<pre class="brush:bash;ruler:true;">
		env workdir=/pool1 cbsd jconstruct-tui
		env workdir=/pool2 cbsd jconstruct-tui
		</pre>
		<p>и тд.</p>
		<p>Каждое окружение будет обслуживать небольшой агент (назовем его bs_router) который будет подключаться к beanstalkd и обрабатывать запросы. Склонируем его:</p>
		<pre class="brush:bash;ruler:true;">
		cd /root
		git clone https://github.com/cbsd/bs_router.git /root/bs_router
		</pre>
		<p>Пример написан на golang, поэтому для сборки проекта нам потребуется go:</p>
		<pre class="brush:bash;ruler:true;">
		pkg install -y lang/go
		</pre>
		<p>Собираем:</p>
		<pre class="brush:bash;ruler:true;">
		cd bs_router
		setenv GOPATH /root/bs_router
		go get
		go build
		cp -a bs_router /usr/local/sbin
		</pre>
		<p>Теперь скопируем конфигурационный файл и откорректируем для каждого пула:</p>
		<pre class="brush:bash;ruler:true;">
		cp -a config.json /usr/local/etc/pool1.json
		cp -a config.json /usr/local/etc/pool2.json
		</pre>
		<p>В обоих файлах измените:</p>
		<ul>
			<li><strong>uri</strong> - с 127.0.0.1:1130 на адрес jail, в котором установлен и запущен beanstalkd, например: <strong>172.16.0.3</strong>:1130 (если контейнер bs1 имеет IP 172.16.0.3)</li>
			<li><strong>cbsdenv</strong> - в файле pool1.json это будет /pool1, в файле pool2.json - /pool2</li>
			<li><strong>tube</strong> - на какую трубу подписываемся, для pool1.json пусть это будет "cbsd_pool1", для pool2.json - cbsd_pool2</li>
			<li><strong>reply_tube_prefix</strong> какую трубу используем для ответов, для pool1.json пусть это будет: cbsd_pool1_result_id, для pool2.json - cbsd_pool2_result_id</li>
		</ul>
		<p>Запускаем оба агента с указанием конфигурационного файла:</p>
		<pre class="brush:bash;ruler:true;">
		/usr/local/sbin/bs_router -config /usr/local/etc/pool1.json
		</pre>
		<p>Все, теперь все, что мы будем отправлять в beanstalk очередь с соответствующим именем и соответствующем payload в формате json, будет передано <strong>CBSD</strong> и получен ответ.</p>
		<p>В качестве примера, склонируем семпл клиента к нашему агенту <strong>CBSD</strong>, который будет подключаться к beanstalkd и слать запросы:</p>
		<pre class="brush:bash;ruler:true;">
		cd /root
		git clone https://github.com/cbsd/bs_router-client.git
		cd bs_router-client
		setenv GOPATH /root/bs_router-client
		go get
		go build
		</pre>
		<p>В результате получили бинарный файл <strong>bs_router-client</strong>, который можно теперь использовать для отправки и приеме задач в разные окружения <strong>CBSD</strong>.
		Посмотрите на каталог bin.jail и bin.bhyve, в которых находятся примеры использования.</p>
		<p>Работая с cloud образами, есть смысл сначала 'прогреть' все образы, чтобы создание первой виртуальной машины не тормозило процесс, например для pool1 это можно сделать так:</p>
		<pre class="brush:bash;ruler:true;">
		env workdir=/pool1 cbsd fetch_iso keepname=0 conv2zvol=1 cloud=1 dstdir=default
		</pre>
		<p>После этой команды, вы сможете воспользоваться результатом выполнения скриптов /root/bs_router-client/bin.bhyve/bcreate.sh и /root/bs_router-client/bin.bhyve/bstart.sh без промедления.</p>
	</div>

